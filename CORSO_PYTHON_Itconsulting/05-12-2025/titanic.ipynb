{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c0dde00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "# Assicura installazione plotly\n",
    "try:\n",
    "    import IPython\n",
    "except ImportError:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"plotly\", \"--quiet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "822e0c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import optuna\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, learning_curve\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0827a83",
   "metadata": {},
   "source": [
    "Caricamento dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590c18ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('titanic_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fbd20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5563abd",
   "metadata": {},
   "source": [
    "Pulizia del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7e2e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# controllo righe mancanti \n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb5684a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(df.median(numeric_only = True))\n",
    "df = df.drop_duplicates()\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3613b55e",
   "metadata": {},
   "source": [
    "Encoding delle variabili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9657fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" for col in df.select_dtypes(include='object'):\n",
    "    df[col] = LabelEncoder().fit_transform(df[col]) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b047a1",
   "metadata": {},
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9d6119",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "df['Family'] = df['SibSp'] + df['Parch'] + 1\n",
    "df['IsAlone'] = (df['Family'] == 1).astype(int)\n",
    "\n",
    "# Feature Title da Name\n",
    "df['Title'] = df['Name'].str.extract(r' ([A-Za-z]+)\\.', expand=False)\n",
    "df['Title'] = df['Title'].replace(['Mlle', 'Ms'], 'Miss')\n",
    "df['Title'] = df['Title'].replace('Mme', 'Mrs')\n",
    "rare_titles = ['Dr','Rev','Col','Major','Count','Lady','Sir','Jonkheer','Don','Capt']\n",
    "df['Title'] = df['Title'].replace(rare_titles, 'Rare')\n",
    "\n",
    "# Feature Deck da Cabin\n",
    "df['Deck'] = df['Cabin'].str[0].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3301770f",
   "metadata": {},
   "source": [
    "Rimuovere gli outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caab162",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" num_cols = df.select_dtypes(include = 'number').columns\n",
    "Q1 = df.quantile(0.25)\n",
    "Q3 = df.quantile(0.75)\n",
    "IQR = Q3 - Q1 \n",
    "\n",
    "df = df[~((df < (Q1 - 1.5*IQR)) | (df > (Q3 + 1.5*IQR))).any(axis=1)] \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e638b2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['Fare', 'Age']:\n",
    "    # Calcola IQR dopo aver imputato NaN (uso la mediana per Fare/Age solo per calcolare IQR)\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    \n",
    " \n",
    "    df[col] = np.where(df[col] > upper_bound, upper_bound, \n",
    "                       np.where(df[col] < lower_bound, lower_bound, df[col]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb713c80",
   "metadata": {},
   "source": [
    "Divisione feature e target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9dd530",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = ['Survived', 'PassengerId', 'Name', 'Embarked'])\n",
    "y = df['Survived'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1258e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suddivisione dataset in train e test \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde5f32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8370c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valutazione della presenza di outlier \n",
    "plt.figure(figsize = (10, 6))\n",
    "sns.boxplot(data=df[['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
    "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d15fc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = df.select_dtypes(include = ['object']).columns.tolist()\n",
    "for col in categorical_cols:\n",
    "    df[col] = LabelEncoder().fit_transform(df[col])\n",
    "    \n",
    "    df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378a9d33",
   "metadata": {},
   "source": [
    "Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3124ac76",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = X_train.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_features = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Pipeline Numerica: Imputazione e Standardizzazione\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')), # Gestisce NaN in Age/Fare\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Pipeline Categorica: Imputazione e One-Hot Encoding\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')), # Gestisce NaN in Embarked/Title/Deck\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# Combinazione\n",
    "preprocessor_raw = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder='drop' # Ignora le colonne non specificate (come 'Sex' e 'Pclass' che sono giÃ  numeriche ma usate come 'object')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7355182d",
   "metadata": {},
   "source": [
    "Modelli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb5e9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_raw(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 600),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'logloss',\n",
    "        'n_jobs': -1,\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBClassifier(**params)\n",
    "\n",
    "    clf = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor_raw),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "    return scores.mean()\n",
    "\n",
    "\n",
    "study_raw = optuna.create_study(direction='maximize')\n",
    "study_raw.optimize(objective_raw, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "print(f\"\\nBest CV Accuracy: {study_raw.best_value:.4f}\")\n",
    "print(\"Best params:\", study_raw.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a15078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# TRAINING MODELLO RAW FINALE\n",
    "# ================================\n",
    "\n",
    "\n",
    "best_params_raw = study_raw.best_params\n",
    "\n",
    "\n",
    "final_pipeline_raw = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor_raw),\n",
    "    ('model', xgb.XGBClassifier(**best_params_raw, random_state=42, use_label_encoder=False))\n",
    "])\n",
    "\n",
    "# Fitting sul train set\n",
    "final_pipeline_raw.fit(X_train, y_train)\n",
    "\n",
    "# Predizioni sul test set\n",
    "y_pred_raw = final_pipeline_raw.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "acc_raw = accuracy_score(y_test, y_pred_raw)\n",
    "\n",
    "# ================================\n",
    "# STAMPA RISULTATI\n",
    "# ================================\n",
    "prev_fe_acc = 0.8400 \n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\" RISULTATI DELLO STUDIO DI ABLAZIONE \")\n",
    "print(\"=\"*50)\n",
    "print(f\"Modello con Feature Engineering (Prev.):  {prev_fe_acc:.4f}\") \n",
    "print(f\"Modello su Dati Raw (Attuale):           {acc_raw:.4f}\")\n",
    "print(\"-\" * 50)\n",
    "delta = (prev_fe_acc - acc_raw) * 100\n",
    "print(f\"Delta Performance: {delta:.2f} punti percentuali persi\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd284d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "### A. Matrice di Confusione (CM)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"\\nGenerazione Matrice di Confusione...\")\n",
    "cm = confusion_matrix(y_test, y_pred_raw)\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Deceduto (0)','Sopravvissuto (1)'], \n",
    "            yticklabels=['Deceduto (0)','Sopravvissuto (1)'])\n",
    "plt.title(\"Matrice di Confusione\")\n",
    "plt.ylabel(\"Valori Reali\")\n",
    "plt.xlabel(\"Predizioni del Modello\")\n",
    "plt.show() # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a52bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## B. Curva di Apprendimento\n",
    "print(\"\\nGenerazione Curva di Apprendimento (Diagnosi Bias/Varianza)...\")\n",
    "try:\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator=final_pipeline_raw, \n",
    "        X=X_train, y=y_train, \n",
    "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42), \n",
    "        n_jobs=-1, \n",
    "        train_sizes=np.linspace(0.1, 1.0, 5), \n",
    "        scoring='accuracy'\n",
    "    )\n",
    "    \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Punteggio Training\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Punteggio Cross-Validation\")\n",
    "    plt.title(\"Curva di Apprendimento (Diagnosi Performance)\")\n",
    "    plt.xlabel(\"Dimensione del Set di Addestramento\")\n",
    "    plt.ylabel(\"Accuratezza\")\n",
    "    plt.grid()\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show() \n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Errore nella Curva di Apprendimento: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
